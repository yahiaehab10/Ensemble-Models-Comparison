{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GlassTypePrediction\n",
    "Responsibility : Mariam Amr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For data preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For implementing ensemble models\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    ")\n",
    "\n",
    "# For hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# For model evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# For visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"./AMLAss1Datasets/glasstypePrediction.csv\"\n",
    ")  # Suitable for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "* Dataset has no nulls\n",
    "* All columns will be used in our project\n",
    "* Scaling the numerical features \n",
    "    ```python\n",
    "    StandardScaler() #Scaling data to fit a standard normal distribution\n",
    "    ```\n",
    "* Removing outliers using `IQR` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the columns\n",
    "df.columns = [\n",
    "    \"ri\", \"na\", \"mg\", \"al\", \"si\", \"k\", \"ca\", \"ba\", \"fe\", \"type\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the numerical features\n",
    "scaler = StandardScaler()\n",
    "df[[\"ri\", \"na\", \"mg\", \"al\", \"si\", \"k\", \"ca\", \"ba\", \"fe\"]] = scaler.fit_transform(\n",
    "    df[[\"ri\", \"na\", \"mg\", \"al\", \"si\", \"k\", \"ca\", \"ba\", \"fe\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ri</th>\n",
       "      <th>na</th>\n",
       "      <th>mg</th>\n",
       "      <th>al</th>\n",
       "      <th>si</th>\n",
       "      <th>k</th>\n",
       "      <th>ca</th>\n",
       "      <th>ba</th>\n",
       "      <th>fe</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.872868</td>\n",
       "      <td>0.284953</td>\n",
       "      <td>1.254639</td>\n",
       "      <td>-0.692442</td>\n",
       "      <td>-1.127082</td>\n",
       "      <td>-0.671705</td>\n",
       "      <td>-0.145766</td>\n",
       "      <td>-0.352877</td>\n",
       "      <td>-0.586451</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.249333</td>\n",
       "      <td>0.591817</td>\n",
       "      <td>0.636168</td>\n",
       "      <td>-0.170460</td>\n",
       "      <td>0.102319</td>\n",
       "      <td>-0.026213</td>\n",
       "      <td>-0.793734</td>\n",
       "      <td>-0.352877</td>\n",
       "      <td>-0.586451</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.721318</td>\n",
       "      <td>0.149933</td>\n",
       "      <td>0.601422</td>\n",
       "      <td>0.190912</td>\n",
       "      <td>0.438787</td>\n",
       "      <td>-0.164533</td>\n",
       "      <td>-0.828949</td>\n",
       "      <td>-0.352877</td>\n",
       "      <td>-0.586451</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.232831</td>\n",
       "      <td>-0.242853</td>\n",
       "      <td>0.698710</td>\n",
       "      <td>-0.310994</td>\n",
       "      <td>-0.052974</td>\n",
       "      <td>0.112107</td>\n",
       "      <td>-0.519052</td>\n",
       "      <td>-0.352877</td>\n",
       "      <td>-0.586451</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.312045</td>\n",
       "      <td>-0.169205</td>\n",
       "      <td>0.650066</td>\n",
       "      <td>-0.411375</td>\n",
       "      <td>0.555256</td>\n",
       "      <td>0.081369</td>\n",
       "      <td>-0.624699</td>\n",
       "      <td>-0.352877</td>\n",
       "      <td>-0.586451</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ri        na        mg        al        si         k        ca  \\\n",
       "0  0.872868  0.284953  1.254639 -0.692442 -1.127082 -0.671705 -0.145766   \n",
       "1 -0.249333  0.591817  0.636168 -0.170460  0.102319 -0.026213 -0.793734   \n",
       "2 -0.721318  0.149933  0.601422  0.190912  0.438787 -0.164533 -0.828949   \n",
       "3 -0.232831 -0.242853  0.698710 -0.310994 -0.052974  0.112107 -0.519052   \n",
       "4 -0.312045 -0.169205  0.650066 -0.411375  0.555256  0.081369 -0.624699   \n",
       "\n",
       "         ba        fe  type  \n",
       "0 -0.352877 -0.586451     1  \n",
       "1 -0.352877 -0.586451     1  \n",
       "2 -0.352877 -0.586451     1  \n",
       "3 -0.352877 -0.586451     1  \n",
       "4 -0.352877 -0.586451     1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Implementation & Hyperparameter Turning\n",
    "\n",
    "References :\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "y = df[\"type\"]\n",
    "X = df.drop(\"type\", axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#random_state here is used to randomly split the data into train and test sets (randomize data before split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier default parameters:\n",
      "Accuracy: 0.8372093023255814\n",
      "Precision: 0.9127314814814816\n",
      "Recall: 0.8432539682539683\n",
      "F1 Score: 0.8605223570909845\n"
     ]
    }
   ],
   "source": [
    "#random_state here and in the other models introduces randomness when splitting and selecting the feature subsets but also when comparing models, setting random_state to the same value will make the comparison fair (instead of using internal randomness)\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "#Performance\n",
    "accuracy_rf = accuracy_score(y_test, y_pred)\n",
    "precision_rf = precision_score(y_test, y_pred, average=\"macro\")\n",
    "recall_rf = recall_score(y_test, y_pred, average=\"macro\")\n",
    "f1_rf = f1_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "print(\"Random Forest Classifier default parameters:\")\n",
    "print(\"Accuracy:\", accuracy_rf)\n",
    "print(\"Precision:\", precision_rf)\n",
    "print(\"Recall:\", recall_rf)\n",
    "print(\"F1 Score:\", f1_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest Classifier:\n",
      "{'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter Tuning with RandomSearchCV\n",
    "params={\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5,10],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "rf_random = RandomizedSearchCV(rf_model, param_distributions=params, n_iter=100, cv=5)\n",
    "\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Random Forest Classifier:\")\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest Classifier from Grid Search:\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter Tuning with GridSearchCV\n",
    "rf_grid = GridSearchCV(rf_model, param_grid=params, cv=5, n_jobs=-1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Random Forest Classifier from Grid Search:\")\n",
    "print(rf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Comparison between initial and tuned models\n",
    "\n",
    "#Tuned model\n",
    "rf_model_tuned = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    criterion='entropy',\n",
    "    max_depth=10,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=2,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    ")\n",
    "rf_model_tuned.fit(X_train, y_train)\n",
    "y_pred_tuned = rf_model_tuned.predict(X_test)\n",
    "\n",
    "accuracy_rf_tuned = accuracy_score(y_test, y_pred_tuned)\n",
    "precision_rf_tuned = precision_score(y_test, y_pred_tuned, average=\"macro\")\n",
    "recall_rf_tuned = recall_score(y_test, y_pred_tuned, average=\"macro\")\n",
    "f1_rf_tuned = f1_score(y_test, y_pred_tuned, average=\"macro\")\n",
    "\n",
    "print(\"Random Forest Classifier tuned parameters:\")\n",
    "print(\"Accuracy:\", accuracy_rf_tuned)\n",
    "print(\"Precision:\", precision_rf_tuned)\n",
    "print(\"Recall:\", recall_rf_tuned)\n",
    "print(\"F1 Score:\", f1_rf_tuned)\n",
    "\n",
    "#Initial model\n",
    "print(\"Random Forest Classifier default parameters:\")\n",
    "print(\"Accuracy:\", accuracy_rf)\n",
    "print(\"Precision:\", precision_rf)\n",
    "print(\"Recall:\", recall_rf)\n",
    "print(\"F1 Score:\", f1_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_model = AdaBoostClassifier(random_state=42)\n",
    "ab_model.fit(X_train, y_train)\n",
    "y_pred = ab_model.predict(X_test)\n",
    "\n",
    "#Performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "print(\"AdaBoost Classifier default parameters performance:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter Tuning with RandomSearchCV\n",
    "params={\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "ab_random = RandomizedSearchCV(ab_model, param_distributions=params, n_iter=100, cv=5)\n",
    "ab_random.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for AdaBoost Classifier with Random Search:\")\n",
    "print(ab_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter Tuning with GridSearchCV\n",
    "ab_grid = GridSearchCV(ab_model, param_grid=params, cv=5)\n",
    "ab_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for AdaBoost Classifier from Grid Search:\")\n",
    "print(ab_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Comparison between initial and tuned models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred = gb_model.predict(X_test)\n",
    "\n",
    "#Performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "print(\"Gradient Boosting Classifier default parameters performance:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter Tuning with RandomSearchCV\n",
    "params={\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1,1.5],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "gb_random = RandomizedSearchCV(gb_model, param_distributions=params, n_iter=100, cv=5)\n",
    "gb_random.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Gradient Boosting Classifier with Random Search:\")\n",
    "print(gb_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter Tuning with GridSearchCV\n",
    "gb_grid = GridSearchCV(gb_model, param_grid=params, cv=5)\n",
    "gb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Gradient Boosting Classifier from Grid Search:\")\n",
    "print(gb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Comparison between initial and tuned models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
